<?xml version="1.0" encoding="UTF-8"?>
<Tokens version="1.0">
	<File path="Classes/AWSRekognitionIndexFacesResponse.html">
		
		<Token>
			<TokenIdentifier>//apple_ref/occ/cl/AWSRekognitionIndexFacesResponse</TokenIdentifier>
			<Abstract type="html"></Abstract>
			<DeclaredIn>AWSRekognitionModel.h</DeclaredIn>
            
			
			<NodeRef refid="1728"/>
		</Token>
		
		
		<Token>
			<TokenIdentifier>//apple_ref/occ/instm/AWSRekognitionIndexFacesResponse/setFaceModelVersion:</TokenIdentifier>
			<Abstract type="html">&lt;p&gt;Version number of the face detection model associated with the input collection (&lt;code&gt;CollectionId&lt;/code&gt;).&lt;/p&gt;</Abstract>
			<DeclaredIn>AWSRekognitionModel.h</DeclaredIn>
			
			<Declaration>@property (nonatomic, strong) NSString *faceModelVersion</Declaration>
			
			
			<Anchor>//api/name/faceModelVersion</Anchor>
            <NodeRef refid="1728"/>
		</Token>
		
		<Token>
			<TokenIdentifier>//apple_ref/occ/instm/AWSRekognitionIndexFacesResponse/faceModelVersion</TokenIdentifier>
			<Abstract type="html">&lt;p&gt;Version number of the face detection model associated with the input collection (&lt;code&gt;CollectionId&lt;/code&gt;).&lt;/p&gt;</Abstract>
			<DeclaredIn>AWSRekognitionModel.h</DeclaredIn>
			
			<Declaration>@property (nonatomic, strong) NSString *faceModelVersion</Declaration>
			
			
			<Anchor>//api/name/faceModelVersion</Anchor>
            <NodeRef refid="1728"/>
		</Token>
		
		<Token>
			<TokenIdentifier>//apple_ref/occ/instp/AWSRekognitionIndexFacesResponse/faceModelVersion</TokenIdentifier>
			<Abstract type="html">&lt;p&gt;Version number of the face detection model associated with the input collection (&lt;code&gt;CollectionId&lt;/code&gt;).&lt;/p&gt;</Abstract>
			<DeclaredIn>AWSRekognitionModel.h</DeclaredIn>
			
			<Declaration>@property (nonatomic, strong) NSString *faceModelVersion</Declaration>
			
			
			<Anchor>//api/name/faceModelVersion</Anchor>
            <NodeRef refid="1728"/>
		</Token>
		
		<Token>
			<TokenIdentifier>//apple_ref/occ/instm/AWSRekognitionIndexFacesResponse/setFaceRecords:</TokenIdentifier>
			<Abstract type="html">&lt;p&gt;An array of faces detected and added to the collection. For more information, see Searching Faces in a Collection in the Amazon Rekognition Developer Guide. &lt;/p&gt;</Abstract>
			<DeclaredIn>AWSRekognitionModel.h</DeclaredIn>
			
			<Declaration>@property (nonatomic, strong) NSArray&lt;AWSRekognitionFaceRecord*&gt; *faceRecords</Declaration>
			
			
			<Anchor>//api/name/faceRecords</Anchor>
            <NodeRef refid="1728"/>
		</Token>
		
		<Token>
			<TokenIdentifier>//apple_ref/occ/instm/AWSRekognitionIndexFacesResponse/faceRecords</TokenIdentifier>
			<Abstract type="html">&lt;p&gt;An array of faces detected and added to the collection. For more information, see Searching Faces in a Collection in the Amazon Rekognition Developer Guide. &lt;/p&gt;</Abstract>
			<DeclaredIn>AWSRekognitionModel.h</DeclaredIn>
			
			<Declaration>@property (nonatomic, strong) NSArray&lt;AWSRekognitionFaceRecord*&gt; *faceRecords</Declaration>
			
			
			<Anchor>//api/name/faceRecords</Anchor>
            <NodeRef refid="1728"/>
		</Token>
		
		<Token>
			<TokenIdentifier>//apple_ref/occ/instp/AWSRekognitionIndexFacesResponse/faceRecords</TokenIdentifier>
			<Abstract type="html">&lt;p&gt;An array of faces detected and added to the collection. For more information, see Searching Faces in a Collection in the Amazon Rekognition Developer Guide. &lt;/p&gt;</Abstract>
			<DeclaredIn>AWSRekognitionModel.h</DeclaredIn>
			
			<Declaration>@property (nonatomic, strong) NSArray&lt;AWSRekognitionFaceRecord*&gt; *faceRecords</Declaration>
			
			
			<Anchor>//api/name/faceRecords</Anchor>
            <NodeRef refid="1728"/>
		</Token>
		
		<Token>
			<TokenIdentifier>//apple_ref/occ/instm/AWSRekognitionIndexFacesResponse/setOrientationCorrection:</TokenIdentifier>
			<Abstract type="html">&lt;p&gt;The orientation of the input image (counterclockwise direction). If your application displays the image, you can use this value to correct image orientation. The bounding box coordinates returned in &lt;code&gt;FaceRecords&lt;/code&gt; represent face locations before the image orientation is corrected. &lt;/p&gt;&lt;note&gt;&lt;p&gt;If the input image is in jpeg format, it might contain exchangeable image (Exif) metadata. If so, and the Exif metadata populates the orientation field, the value of &lt;code&gt;OrientationCorrection&lt;/code&gt; is null and the bounding box coordinates in &lt;code&gt;FaceRecords&lt;/code&gt; represent face locations after Exif metadata is used to correct the image orientation. Images in .png format don&apos;t contain Exif metadata.&lt;/p&gt;&lt;/note&gt;</Abstract>
			<DeclaredIn>AWSRekognitionModel.h</DeclaredIn>
			
			<Declaration>@property (nonatomic, assign) AWSRekognitionOrientationCorrection orientationCorrection</Declaration>
			
			
			<Anchor>//api/name/orientationCorrection</Anchor>
            <NodeRef refid="1728"/>
		</Token>
		
		<Token>
			<TokenIdentifier>//apple_ref/occ/instm/AWSRekognitionIndexFacesResponse/orientationCorrection</TokenIdentifier>
			<Abstract type="html">&lt;p&gt;The orientation of the input image (counterclockwise direction). If your application displays the image, you can use this value to correct image orientation. The bounding box coordinates returned in &lt;code&gt;FaceRecords&lt;/code&gt; represent face locations before the image orientation is corrected. &lt;/p&gt;&lt;note&gt;&lt;p&gt;If the input image is in jpeg format, it might contain exchangeable image (Exif) metadata. If so, and the Exif metadata populates the orientation field, the value of &lt;code&gt;OrientationCorrection&lt;/code&gt; is null and the bounding box coordinates in &lt;code&gt;FaceRecords&lt;/code&gt; represent face locations after Exif metadata is used to correct the image orientation. Images in .png format don&apos;t contain Exif metadata.&lt;/p&gt;&lt;/note&gt;</Abstract>
			<DeclaredIn>AWSRekognitionModel.h</DeclaredIn>
			
			<Declaration>@property (nonatomic, assign) AWSRekognitionOrientationCorrection orientationCorrection</Declaration>
			
			
			<Anchor>//api/name/orientationCorrection</Anchor>
            <NodeRef refid="1728"/>
		</Token>
		
		<Token>
			<TokenIdentifier>//apple_ref/occ/instp/AWSRekognitionIndexFacesResponse/orientationCorrection</TokenIdentifier>
			<Abstract type="html">&lt;p&gt;The orientation of the input image (counterclockwise direction). If your application displays the image, you can use this value to correct image orientation. The bounding box coordinates returned in &lt;code&gt;FaceRecords&lt;/code&gt; represent face locations before the image orientation is corrected. &lt;/p&gt;&lt;note&gt;&lt;p&gt;If the input image is in jpeg format, it might contain exchangeable image (Exif) metadata. If so, and the Exif metadata populates the orientation field, the value of &lt;code&gt;OrientationCorrection&lt;/code&gt; is null and the bounding box coordinates in &lt;code&gt;FaceRecords&lt;/code&gt; represent face locations after Exif metadata is used to correct the image orientation. Images in .png format don&apos;t contain Exif metadata.&lt;/p&gt;&lt;/note&gt;</Abstract>
			<DeclaredIn>AWSRekognitionModel.h</DeclaredIn>
			
			<Declaration>@property (nonatomic, assign) AWSRekognitionOrientationCorrection orientationCorrection</Declaration>
			
			
			<Anchor>//api/name/orientationCorrection</Anchor>
            <NodeRef refid="1728"/>
		</Token>
		
        
        
	</File>
</Tokens>