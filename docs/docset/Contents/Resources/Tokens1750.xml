<?xml version="1.0" encoding="UTF-8"?>
<Tokens version="1.0">
	<File path="Classes/AWSRekognitionRecognizeCelebritiesResponse.html">
		
		<Token>
			<TokenIdentifier>//apple_ref/occ/cl/AWSRekognitionRecognizeCelebritiesResponse</TokenIdentifier>
			<Abstract type="html"></Abstract>
			<DeclaredIn>AWSRekognitionModel.h</DeclaredIn>
            
			
			<NodeRef refid="1750"/>
		</Token>
		
		
		<Token>
			<TokenIdentifier>//apple_ref/occ/instm/AWSRekognitionRecognizeCelebritiesResponse/setCelebrityFaces:</TokenIdentifier>
			<Abstract type="html">&lt;p&gt;Details about each celebrity found in the image. Amazon Rekognition can detect a maximum of 15 celebrities in an image.&lt;/p&gt;</Abstract>
			<DeclaredIn>AWSRekognitionModel.h</DeclaredIn>
			
			<Declaration>@property (nonatomic, strong) NSArray&lt;AWSRekognitionCelebrity*&gt; *celebrityFaces</Declaration>
			
			
			<Anchor>//api/name/celebrityFaces</Anchor>
            <NodeRef refid="1750"/>
		</Token>
		
		<Token>
			<TokenIdentifier>//apple_ref/occ/instm/AWSRekognitionRecognizeCelebritiesResponse/celebrityFaces</TokenIdentifier>
			<Abstract type="html">&lt;p&gt;Details about each celebrity found in the image. Amazon Rekognition can detect a maximum of 15 celebrities in an image.&lt;/p&gt;</Abstract>
			<DeclaredIn>AWSRekognitionModel.h</DeclaredIn>
			
			<Declaration>@property (nonatomic, strong) NSArray&lt;AWSRekognitionCelebrity*&gt; *celebrityFaces</Declaration>
			
			
			<Anchor>//api/name/celebrityFaces</Anchor>
            <NodeRef refid="1750"/>
		</Token>
		
		<Token>
			<TokenIdentifier>//apple_ref/occ/instp/AWSRekognitionRecognizeCelebritiesResponse/celebrityFaces</TokenIdentifier>
			<Abstract type="html">&lt;p&gt;Details about each celebrity found in the image. Amazon Rekognition can detect a maximum of 15 celebrities in an image.&lt;/p&gt;</Abstract>
			<DeclaredIn>AWSRekognitionModel.h</DeclaredIn>
			
			<Declaration>@property (nonatomic, strong) NSArray&lt;AWSRekognitionCelebrity*&gt; *celebrityFaces</Declaration>
			
			
			<Anchor>//api/name/celebrityFaces</Anchor>
            <NodeRef refid="1750"/>
		</Token>
		
		<Token>
			<TokenIdentifier>//apple_ref/occ/instm/AWSRekognitionRecognizeCelebritiesResponse/setOrientationCorrection:</TokenIdentifier>
			<Abstract type="html">&lt;p&gt;The orientation of the input image (counterclockwise direction). If your application displays the image, you can use this value to correct the orientation. The bounding box coordinates returned in &lt;code&gt;CelebrityFaces&lt;/code&gt; and &lt;code&gt;UnrecognizedFaces&lt;/code&gt; represent face locations before the image orientation is corrected. &lt;/p&gt;&lt;note&gt;&lt;p&gt;If the input image is in .jpeg format, it might contain exchangeable image (Exif) metadata that includes the image&apos;s orientation. If so, and the Exif metadata for the input image populates the orientation field, the value of &lt;code&gt;OrientationCorrection&lt;/code&gt; is null and the &lt;code&gt;CelebrityFaces&lt;/code&gt; and &lt;code&gt;UnrecognizedFaces&lt;/code&gt; bounding box coordinates represent face locations after Exif metadata is used to correct the image orientation. Images in .png format don&apos;t contain Exif metadata. &lt;/p&gt;&lt;/note&gt;</Abstract>
			<DeclaredIn>AWSRekognitionModel.h</DeclaredIn>
			
			<Declaration>@property (nonatomic, assign) AWSRekognitionOrientationCorrection orientationCorrection</Declaration>
			
			
			<Anchor>//api/name/orientationCorrection</Anchor>
            <NodeRef refid="1750"/>
		</Token>
		
		<Token>
			<TokenIdentifier>//apple_ref/occ/instm/AWSRekognitionRecognizeCelebritiesResponse/orientationCorrection</TokenIdentifier>
			<Abstract type="html">&lt;p&gt;The orientation of the input image (counterclockwise direction). If your application displays the image, you can use this value to correct the orientation. The bounding box coordinates returned in &lt;code&gt;CelebrityFaces&lt;/code&gt; and &lt;code&gt;UnrecognizedFaces&lt;/code&gt; represent face locations before the image orientation is corrected. &lt;/p&gt;&lt;note&gt;&lt;p&gt;If the input image is in .jpeg format, it might contain exchangeable image (Exif) metadata that includes the image&apos;s orientation. If so, and the Exif metadata for the input image populates the orientation field, the value of &lt;code&gt;OrientationCorrection&lt;/code&gt; is null and the &lt;code&gt;CelebrityFaces&lt;/code&gt; and &lt;code&gt;UnrecognizedFaces&lt;/code&gt; bounding box coordinates represent face locations after Exif metadata is used to correct the image orientation. Images in .png format don&apos;t contain Exif metadata. &lt;/p&gt;&lt;/note&gt;</Abstract>
			<DeclaredIn>AWSRekognitionModel.h</DeclaredIn>
			
			<Declaration>@property (nonatomic, assign) AWSRekognitionOrientationCorrection orientationCorrection</Declaration>
			
			
			<Anchor>//api/name/orientationCorrection</Anchor>
            <NodeRef refid="1750"/>
		</Token>
		
		<Token>
			<TokenIdentifier>//apple_ref/occ/instp/AWSRekognitionRecognizeCelebritiesResponse/orientationCorrection</TokenIdentifier>
			<Abstract type="html">&lt;p&gt;The orientation of the input image (counterclockwise direction). If your application displays the image, you can use this value to correct the orientation. The bounding box coordinates returned in &lt;code&gt;CelebrityFaces&lt;/code&gt; and &lt;code&gt;UnrecognizedFaces&lt;/code&gt; represent face locations before the image orientation is corrected. &lt;/p&gt;&lt;note&gt;&lt;p&gt;If the input image is in .jpeg format, it might contain exchangeable image (Exif) metadata that includes the image&apos;s orientation. If so, and the Exif metadata for the input image populates the orientation field, the value of &lt;code&gt;OrientationCorrection&lt;/code&gt; is null and the &lt;code&gt;CelebrityFaces&lt;/code&gt; and &lt;code&gt;UnrecognizedFaces&lt;/code&gt; bounding box coordinates represent face locations after Exif metadata is used to correct the image orientation. Images in .png format don&apos;t contain Exif metadata. &lt;/p&gt;&lt;/note&gt;</Abstract>
			<DeclaredIn>AWSRekognitionModel.h</DeclaredIn>
			
			<Declaration>@property (nonatomic, assign) AWSRekognitionOrientationCorrection orientationCorrection</Declaration>
			
			
			<Anchor>//api/name/orientationCorrection</Anchor>
            <NodeRef refid="1750"/>
		</Token>
		
		<Token>
			<TokenIdentifier>//apple_ref/occ/instm/AWSRekognitionRecognizeCelebritiesResponse/setUnrecognizedFaces:</TokenIdentifier>
			<Abstract type="html">&lt;p&gt;Details about each unrecognized face in the image.&lt;/p&gt;</Abstract>
			<DeclaredIn>AWSRekognitionModel.h</DeclaredIn>
			
			<Declaration>@property (nonatomic, strong) NSArray&lt;AWSRekognitionComparedFace*&gt; *unrecognizedFaces</Declaration>
			
			
			<Anchor>//api/name/unrecognizedFaces</Anchor>
            <NodeRef refid="1750"/>
		</Token>
		
		<Token>
			<TokenIdentifier>//apple_ref/occ/instm/AWSRekognitionRecognizeCelebritiesResponse/unrecognizedFaces</TokenIdentifier>
			<Abstract type="html">&lt;p&gt;Details about each unrecognized face in the image.&lt;/p&gt;</Abstract>
			<DeclaredIn>AWSRekognitionModel.h</DeclaredIn>
			
			<Declaration>@property (nonatomic, strong) NSArray&lt;AWSRekognitionComparedFace*&gt; *unrecognizedFaces</Declaration>
			
			
			<Anchor>//api/name/unrecognizedFaces</Anchor>
            <NodeRef refid="1750"/>
		</Token>
		
		<Token>
			<TokenIdentifier>//apple_ref/occ/instp/AWSRekognitionRecognizeCelebritiesResponse/unrecognizedFaces</TokenIdentifier>
			<Abstract type="html">&lt;p&gt;Details about each unrecognized face in the image.&lt;/p&gt;</Abstract>
			<DeclaredIn>AWSRekognitionModel.h</DeclaredIn>
			
			<Declaration>@property (nonatomic, strong) NSArray&lt;AWSRekognitionComparedFace*&gt; *unrecognizedFaces</Declaration>
			
			
			<Anchor>//api/name/unrecognizedFaces</Anchor>
            <NodeRef refid="1750"/>
		</Token>
		
        
        
	</File>
</Tokens>